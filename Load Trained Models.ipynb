{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b90ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from itertools import cycle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
    "import random\n",
    "from scipy.interpolate import CubicSpline\n",
    "%matplotlib inline\n",
    "tf.__version__\n",
    "#from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d261127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_test():\n",
    "#     #Test ori data\n",
    "#     test_x = np.load(\"D:/Research/Datasets/Time_series/MIT Processed/Test Dataset/ecg_ori_all_reshaped_te_segments.npy\")\n",
    "#     test_y = np.load(\"D:/Research/Datasets/Time_series/MIT Processed/Test Dataset/ecg_ori_all_te_labels.npy\")\n",
    "\n",
    "#     print(test_x.shape)\n",
    "#     print(test_y)\n",
    "#     return test_x,test_y\n",
    "\n",
    "def load_test():\n",
    "    #Test ori data\n",
    "    test_x = np.load(r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Data-20240119T210557Z-001\\Data\\MIT Processed\\Test Dataset\\ecg_ori_all_reshaped_te_segments.npy\")\n",
    "    test_y = np.load(r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Data-20240119T210557Z-001\\Data\\MIT Processed\\Test Dataset\\ecg_ori_all_te_labels.npy\")\n",
    "\n",
    "    print(test_x.shape)\n",
    "    print(test_y)\n",
    "    return test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f678ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_train():\n",
    "#     #Test ori data\n",
    "#     train_x = np.load(\"D:/Research/Datasets/Time_series/MIT Processed/Train Dataset/Original/ecg_ori_all_reshaped_tr_segments.npy\")\n",
    "#     train_y = np.load(\"D:/Research/Datasets/Time_series/MIT Processed/Train Dataset/Original/ecg_ori_all_tr_labels.npy\")\n",
    "\n",
    "#     print(train_x.shape)\n",
    "#     print(train_y)\n",
    "#     return train_x,train_y\n",
    "\n",
    "def load_train():\n",
    "    #Test ori data\n",
    "    train_x = np.load(r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Data-20240119T210557Z-001\\Data\\MIT Processed\\Train Dataset\\Original\\ecg_ori_all_reshaped_tr_segments.npy\")\n",
    "    train_y = np.load(r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Data-20240119T210557Z-001\\Data\\MIT Processed\\Train Dataset\\Original\\ecg_ori_all_tr_labels.npy\")\n",
    "\n",
    "    print(train_x.shape)\n",
    "    print(train_y)\n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be9b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 1800, 1)\n",
      "[1 3 0 0 3 2 2 1 2 0 3 0 2 1 3 3 2 0 0 0 0 0 0 0 1 2 0 0 0 2 3 0 0 1 1 0 0\n",
      " 3 0 0 3 2 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 3 1 0 0 0 0 0 0 2 0 1 1 3 1 0 1 0\n",
      " 0 0 1 3 1 0 2 0 2 1 1 2 2 1 0 1 1 2 0 2 0 0 0 2 2 3 2 0 1 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 3 3 2 2 3 3 2 0 0 0 1 0 3 2 1 2 2 1 2 1 3 0 1 2 0 0 0 1 0 0 0 1 3\n",
      " 0 0 0 1 0 0 0 3 1 1 1 2 1 1 2 0 0 0 0 1 0 3 0 0 3 2 0 1 3 3 2 1 0 0 0 0 2\n",
      " 2 3 1 2 2 2 0 2 1 0 1 0 2 1 1 0 3 3 3 0 2 0 2 2 1 1 1 1 1 0 0 2 0 2 0 0 3\n",
      " 1 1 3 0 1 1 0 0 0 3 0 0 1 0 0 0 2 3 0 2 0 2 0 3 2 1 0 1 0 3 3 0 0 0 2 2 0\n",
      " 0 3 1 0 1 1 0 0 0 2 0 2 2 0 3 3 0 1 0 3 0 0 2 0 1 3 2 1 0 1 3 3 2 0 2 1 2\n",
      " 2 0 0 0 2 0 2 1 2 0 0 1 2 3 0 2 0 2 3 1 0 3 2 3 1 0 3 1 0 1 0 3 0 0 1 2 1\n",
      " 3 1 0 0 2 3 0 1 2 2 3 0 3 0 2 0 0 0 0 0 1 0 1 1 0 2 0 2 0 3 2 0 1 1 0 1 0\n",
      " 3 2 1 3 0 1 0 0 0 0 3 3 0 0 2 0 2 1 0 0 2 3 3 2 2 2 2 0 2 0 1 2 0 3 2 0 0\n",
      " 0 0 2 0 1 0 3 3 0 1 2 0 0 0 3 0 0 2 0 1 2 3 2 2 0 2 0 0 1 0 3 3 0 3 0 2 2\n",
      " 1 2 0 0 3 1 3 0 3 1 3 0 3 0 3 2]\n",
      "(192, 1800, 1)\n",
      "[1 2 3 0 1 0 2 1 0 0 2 2 3 1 1 0 0 0 0 1 1 0 2 0 0 0 2 1 0 0 0 1 0 2 3 0 0\n",
      " 1 0 0 1 1 2 0 0 2 2 2 2 2 0 0 0 0 1 0 1 0 1 0 1 0 0 1 2 0 3 3 0 0 0 1 1 3\n",
      " 0 3 0 2 3 1 0 2 2 3 0 1 0 0 0 1 2 0 3 2 1 3 0 0 0 2 2 3 2 1 0 0 3 3 0 0 1\n",
      " 0 0 3 0 2 1 3 0 0 3 1 3 2 1 1 0 0 0 0 2 2 2 3 0 0 1 0 2 0 0 3 0 0 2 2 1 2\n",
      " 2 1 3 1 0 3 0 0 0 0 0 2 3 0 3 1 2 3 1 1 0 0 2 0 0 2 0 1 3 3 0 0 3 2 3 0 1\n",
      " 3 0 1 1 0 2 2]\n",
      "(460, 1800, 1) (460,) (192, 1800, 1) (192,)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y = load_train()\n",
    "test_x,test_y = load_test()\n",
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9e9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    model = Sequential()\n",
    "    #model.add(Reshape((time, features), input_shape=(input_shape,)))\n",
    "    model.add(Conv1D(32, 18, name='conv0',activation='relu', input_shape=(1800,1)))\n",
    "    model.add(Conv1D(32, 18, name='conv1',activation='relu'))\n",
    "    model.add(Conv1D(64, 18, name='conv2',activation='relu'))\n",
    "    model.add(Conv1D(64, 18, name='conv3',activation='relu'))\n",
    "    model.add(Conv1D(128, 18, name='conv4',activation='relu'))\n",
    "    model.add(Conv1D(128, 18, name='conv5',activation='relu'))\n",
    "    model.add(Conv1D(256, 18, name='conv6',activation='relu'))\n",
    "    model.add(Conv1D(256, 18, name='conv7',activation='relu'))\n",
    "    model.add(MaxPooling1D(3,name='max1'))\n",
    "    model.add(Conv1D(32, 18, name='conv8',activation='relu'))\n",
    "    model.add(Conv1D(32, 18, name='conv9',activation='relu'))\n",
    "    model.add(Conv1D(64, 18, name='conv10',activation='relu'))\n",
    "    model.add(Conv1D(64, 18, name='conv11',activation='relu'))\n",
    "    model.add(Conv1D(128, 18, name='conv12',activation='relu'))\n",
    "    model.add(Conv1D(256, 18, name='conv13',activation='relu'))\n",
    "    model.add(GlobalAveragePooling1D(name='gap1'))\n",
    "    model.add(Dropout(.5,name='drop1'))\n",
    "    model.add(Dense(4, name='dense1',activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_ckpt(model,path):\n",
    "    model.load_weights(path)\n",
    "    #model.summary()\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(decay=.01,learning_rate=0.001,beta_1=.009,beta_2=.8,epsilon=1e-08), metrics=[tf.keras.metrics.CategoricalAccuracy(\n",
    "        name='accuracy'),tf.keras.metrics.Recall(name='Recall'),tf.keras.metrics.Precision(name='Precision'),tf.keras.metrics.AUC(name='AUC')])\n",
    "        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1591577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv0 (Conv1D)              (None, 1800, 32)          128       \n",
      "                                                                 \n",
      " bn0 (BatchNormalization)    (None, 1800, 32)          128       \n",
      "                                                                 \n",
      " elu0 (ELU)                  (None, 1800, 32)          0         \n",
      "                                                                 \n",
      " dropout0 (Dropout)          (None, 1800, 32)          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 1800, 32)          3104      \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 1800, 32)          128       \n",
      "                                                                 \n",
      " elu1 (ELU)                  (None, 1800, 32)          0         \n",
      "                                                                 \n",
      " max0 (MaxPooling1D)         (None, 600, 32)           0         \n",
      "                                                                 \n",
      " dropout1 (Dropout)          (None, 600, 32)           0         \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 600, 64)           6208      \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 600, 64)           256       \n",
      "                                                                 \n",
      " elu2 (ELU)                  (None, 600, 64)           0         \n",
      "                                                                 \n",
      " dropout2 (Dropout)          (None, 600, 64)           0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 600, 64)           12352     \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 600, 64)           256       \n",
      "                                                                 \n",
      " elu3 (ELU)                  (None, 600, 64)           0         \n",
      "                                                                 \n",
      " max1 (MaxPooling1D)         (None, 200, 64)           0         \n",
      "                                                                 \n",
      " dropout3 (Dropout)          (None, 200, 64)           0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 200, 128)          24704     \n",
      "                                                                 \n",
      " bn4 (BatchNormalization)    (None, 200, 128)          512       \n",
      "                                                                 \n",
      " elu4 (ELU)                  (None, 200, 128)          0         \n",
      "                                                                 \n",
      " dropout4 (Dropout)          (None, 200, 128)          0         \n",
      "                                                                 \n",
      " conv5 (Conv1D)              (None, 200, 128)          49280     \n",
      "                                                                 \n",
      " bn5 (BatchNormalization)    (None, 200, 128)          512       \n",
      "                                                                 \n",
      " elu5 (ELU)                  (None, 200, 128)          0         \n",
      "                                                                 \n",
      " max2 (MaxPooling1D)         (None, 66, 128)           0         \n",
      "                                                                 \n",
      " dropout5 (Dropout)          (None, 66, 128)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8448)              0         \n",
      "                                                                 \n",
      " dense_final (Dense)         (None, 4)                 33796     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,364\n",
      "Trainable params: 130,468\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D,BatchNormalization,Input,ELU\n",
    "\n",
    "def build_improved_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional block 1\n",
    "    model.add(Conv1D(32, kernel_size=3, padding='same', input_shape=(1800, 1), kernel_regularizer=l2(0.001), name='conv0'))\n",
    "    model.add(BatchNormalization(name='bn0'))\n",
    "    model.add(ELU(name='elu0'))\n",
    "    model.add(Dropout(0.2, name='dropout0'))\n",
    "\n",
    "    # Convolutional block 2\n",
    "    model.add(Conv1D(32, kernel_size=3, padding='same', kernel_regularizer=l2(0.001), name='conv1'))\n",
    "    model.add(BatchNormalization(name='bn1'))\n",
    "    model.add(ELU(name='elu1'))\n",
    "    model.add(MaxPooling1D(pool_size=3, name='max0'))\n",
    "    model.add(Dropout(0.2, name='dropout1'))\n",
    "\n",
    "    # Convolutional block 3\n",
    "    model.add(Conv1D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.001), name='conv2'))\n",
    "    model.add(BatchNormalization(name='bn2'))\n",
    "    model.add(ELU(name='elu2'))\n",
    "    model.add(Dropout(0.3, name='dropout2'))\n",
    "\n",
    "    # Convolutional block 4\n",
    "    model.add(Conv1D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.001), name='conv3'))\n",
    "    model.add(BatchNormalization(name='bn3'))\n",
    "    model.add(ELU(name='elu3'))\n",
    "    model.add(MaxPooling1D(pool_size=3, name='max1'))\n",
    "    model.add(Dropout(0.3, name='dropout3'))\n",
    "\n",
    "    # Convolutional block 5\n",
    "    model.add(Conv1D(128, kernel_size=3, padding='same', kernel_regularizer=l2(0.001), name='conv4'))\n",
    "    model.add(BatchNormalization(name='bn4'))\n",
    "    model.add(ELU(name='elu4'))\n",
    "    model.add(Dropout(0.4, name='dropout4'))\n",
    "\n",
    "    # Convolutional block 6\n",
    "    model.add(Conv1D(128, kernel_size=3, padding='same', kernel_regularizer=l2(0.001), name='conv5'))\n",
    "    model.add(BatchNormalization(name='bn5'))\n",
    "    model.add(ELU(name='elu5'))\n",
    "    model.add(MaxPooling1D(pool_size=3, name='max2'))\n",
    "    model.add(Dropout(0.4, name='dropout5'))\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4, activation='softmax', kernel_regularizer=l2(0.001), name='dense_final'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_improved_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c03440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = ['\\Aug_Jitter_T1\\\\Model_144','\\Aug_Permute_T1\\\\Model_93', '\\Aug_rotate_T1\\\\Model_124' ]\n",
    "\n",
    "ckpt=[r\"\\Scale_Model_121\",\n",
    "      r\"\\Jitter_Model_144\",\n",
    "      r\"\\Flip_Model_44\",\n",
    "      r\"\\No_Aug_CustomCNN_Lead0_44\",\n",
    "      r\"\\MagnitudeWarp_Model_102\",\n",
    "      r\"\\Permute_Model_93\",\n",
    "      r\"\\Rotate_Model_124\",\n",
    "      r\"\\TimeWarp_Model_115\",\n",
    "      r\"\\Window_Slice_Model_121\",\n",
    "      r\"\\Window_Warp_Model_114\",]\n",
    "\n",
    "# ckpt=[r\"\\Aug_No_Aug_T2\\No_Aug_Model_145\"]\n",
    "models = []\n",
    "for m in ckpt:\n",
    "    model = classifier()\n",
    "    # path = r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Code-20240119T232854Z-001\\Code\"+ m\n",
    "    path = r\"C:\\Users\\nbalasubramanian\\Documents\\Research Work\\New Data\\Models-20240119T210601Z-001\\Models\" + m\n",
    "    model = load_ckpt(model,path)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03637f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Scale_Model_121\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.5837 - accuracy: 0.9323 - Recall: 0.9271 - Precision: 0.9319 - AUC: 0.9784\n",
      "[0.5836781859397888, 0.9322916865348816, 0.9270833134651184, 0.9319371581077576, 0.9784162044525146]\n",
      "\\Jitter_Model_144\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5198 - accuracy: 0.8906 - Recall: 0.8802 - Precision: 0.8942 - AUC: 0.9798\n",
      "[0.5198450088500977, 0.890625, 0.8802083134651184, 0.8941798806190491, 0.9798357486724854]\n",
      "\\Flip_Model_44\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3627 - accuracy: 0.9115 - Recall: 0.9115 - Precision: 0.9115 - AUC: 0.9780\n",
      "[0.3627232313156128, 0.9114583134651184, 0.9114583134651184, 0.9114583134651184, 0.9780001640319824]\n",
      "\\No_Aug_CustomCNN_Lead0_44\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2782 - accuracy: 0.9010 - Recall: 0.9010 - Precision: 0.9058 - AUC: 0.9864\n",
      "[0.2781948745250702, 0.9010416865348816, 0.9010416865348816, 0.9057591557502747, 0.9863914847373962]\n",
      "\\MagnitudeWarp_Model_102\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.5817 - accuracy: 0.9271 - Recall: 0.9271 - Precision: 0.9319 - AUC: 0.9839\n",
      "[0.5817353129386902, 0.9270833134651184, 0.9270833134651184, 0.9319371581077576, 0.9839138388633728]\n",
      "\\Permute_Model_93\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.1687 - accuracy: 0.9115 - Recall: 0.9115 - Precision: 0.9115 - AUC: 0.9709\n",
      "[1.168652892112732, 0.9114583134651184, 0.9114583134651184, 0.9114583134651184, 0.9708569049835205]\n",
      "\\Rotate_Model_124\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.5840 - accuracy: 0.9062 - Recall: 0.9062 - Precision: 0.9110 - AUC: 0.9736\n",
      "[1.5840158462524414, 0.90625, 0.90625, 0.9109947681427002, 0.9736192226409912]\n",
      "\\TimeWarp_Model_115\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8288 - accuracy: 0.9271 - Recall: 0.9271 - Precision: 0.9271 - AUC: 0.9694\n",
      "[0.8288397789001465, 0.9270833134651184, 0.9270833134651184, 0.9270833134651184, 0.969373881816864]\n",
      "\\Window_Slice_Model_121\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1309 - accuracy: 0.9115 - Recall: 0.9115 - Precision: 0.9115 - AUC: 0.9676\n",
      "[1.1308985948562622, 0.9114583134651184, 0.9114583134651184, 0.9114583134651184, 0.9675790071487427]\n",
      "\\Window_Warp_Model_114\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3703 - accuracy: 0.9219 - Recall: 0.9219 - Precision: 0.9219 - AUC: 0.9868\n",
      "[0.3703092038631439, 0.921875, 0.921875, 0.921875, 0.9868299961090088]\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for m in models:\n",
    "    print(ckpt[c])\n",
    "    print(m.evaluate(test_x,np_utils.to_categorical(test_y, 4)))\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "537f2eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 64ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 23ms/step\n",
      "6/6 [==============================] - 0s 24ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n",
      "6/6 [==============================] - 0s 23ms/step\n",
      "6/6 [==============================] - 0s 23ms/step\n",
      "6/6 [==============================] - 0s 28ms/step\n",
      "6/6 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'predictions_csv'\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.makedirs(predictions_dir)\n",
    "\n",
    "incorrect_predictions = {}\n",
    "\n",
    "for c, model in enumerate(models):\n",
    "    model_name = ckpt[c].replace('\\\\', '').replace('/', '')\n",
    "    output_file = os.path.join(predictions_dir, f'{model_name}_predictions.csv')\n",
    "\n",
    "    predictions = model.predict(test_x)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    correct_predictions = pd.Series(predicted_classes == test_y).replace({True: 'T', False: 'F'})\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Index': range(len(test_y)),\n",
    "        'Predicted Label': predicted_classes,\n",
    "        'True Label': test_y,\n",
    "        'Correct Prediction': correct_predictions\n",
    "    })\n",
    "    incorrect_indices = df[df['Correct Prediction'] == 'F']['Index'].tolist()\n",
    "    incorrect_predictions[model_name] = incorrect_indices\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "incorrect_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in incorrect_predictions.items()]))\n",
    "incorrect_df.to_csv('incorrect_predictions_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
